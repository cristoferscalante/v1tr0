---
title: "El Proceso de Entrenamiento de una Red Neuronal"
date: 2025-10-02
author: "Alvaro Efren BolaÃ±os Scalante"
tags: ["entrenamiento", "backpropagation", "gradient-descent", "optimizaciÃ³n"]
series: "Deep Learning desde Cero"
part: 3
---

# El Proceso de Entrenamiento de una Red Neuronal

## ğŸ¯ IntroducciÃ³n

El entrenamiento de una red neuronal es un **ciclo de optimizaciÃ³n** cuyo objetivo es ajustar los parÃ¡metros del modelo (pesos y sesgos) para minimizar su error.

Este proceso se fundamenta en **tres pilares matemÃ¡ticos**:

1. ğŸ“‰ **FunciÃ³n de Costo**
2. â¬‡ï¸ **Descenso de Gradiente**
3. ğŸ”„ **RetropropagaciÃ³n**

## 1ï¸âƒ£ La FunciÃ³n de Costo: CuantificaciÃ³n del Error

La **funciÃ³n de costo J(w,b)** cuantifica cuÃ¡n equivocadas estÃ¡n las predicciones del modelo.

### AnalogÃ­a
Como una **balanza desequilibrada**: el objetivo es ajustarla hasta alcanzar el equilibrio (error mÃ­nimo).

### FÃ³rmula General

```
J(w,b) = (1/m) Â· Î£ L(yâ½â±â¾, a[L]â½â±â¾)
```

**Componentes:**
- **m**: NÃºmero total de ejemplos de entrenamiento
- **L**: FunciÃ³n de pÃ©rdida (un ejemplo)
- **yâ½â±â¾**: Etiqueta verdadera
- **a[L]â½â±â¾**: PredicciÃ³n del modelo

### Error CuadrÃ¡tico Medio (MSE)

```
L(y, Å·) = (y âˆ’ Å·)Â²
```

```python
import numpy as np

def costo_mse(y_true, y_pred):
    m = len(y_true)
    return (1/m) * np.sum((y_true - y_pred)**2)

# Ejemplo
y_true = np.array([1, 0, 1, 1, 0])
y_pred = np.array([0.9, 0.1, 0.8, 0.7, 0.2])
print(f"Costo: {costo_mse(y_true, y_pred):.4f}")
```

**Objetivo:** Encontrar W y b que minimicen J(w,b).

## 2ï¸âƒ£ Descenso del Gradiente: El Algoritmo de OptimizaciÃ³n

El **Descenso de Gradiente EstocÃ¡stico (SGD)** es el algoritmo mÃ¡s utilizado para minimizar la funciÃ³n de costo.

### ğŸ”ï¸ AnalogÃ­a: Descenso de una MontaÃ±a

Imagina que estÃ¡s en una montaÃ±a con niebla densa. Para bajar:
1. Sientes la pendiente del terreno
2. Das un paso en la direcciÃ³n mÃ¡s inclinada hacia abajo
3. Repites hasta llegar al valle

**MatemÃ¡ticamente:** Moverse en la direcciÃ³n opuesta al gradiente.

### Variante Moderna: Mini-Batch Gradient Descent

Actualiza parÃ¡metros usando un **pequeÃ±o lote** de muestras:
- MÃ¡s eficiente que procesar todo el dataset
- MÃ¡s estable que usar un solo ejemplo

### Pasos del Algoritmo

```python
# PseudocÃ³digo
def entrenar_red(X, y, epochs, learning_rate):
    # 1. InicializaciÃ³n
    W, b = inicializar_parametros_aleatorios()
    
    for epoch in range(epochs):
        for batch in crear_mini_batches(X, y):
            # 2. CÃ¡lculo del gradiente
            gradientes = calcular_gradientes(batch, W, b)
            
            # 3. ActualizaciÃ³n de parÃ¡metros
            W = W - learning_rate * gradientes['dW']
            b = b - learning_rate * gradientes['db']
    
    return W, b
```

### Ecuaciones de ActualizaciÃ³n

```
wâ½â±âºÂ¹â¾ = wâ½â±â¾ âˆ’ Î± Â· (âˆ‚J/âˆ‚w)
bâ½â±âºÂ¹â¾ = bâ½â±â¾ âˆ’ Î± Â· (âˆ‚J/âˆ‚b)
```

**Î±** = **tasa de aprendizaje** (learning rate)
- Muy pequeÃ±a â†’ Convergencia lenta
- Muy grande â†’ Puede no converger

```python
# Ejemplo de actualizaciÃ³n
W_nuevo = W_actual - 0.01 * gradiente_W
b_nuevo = b_actual - 0.01 * gradiente_b
```

## 3ï¸âƒ£ RetropropagaciÃ³n: CÃ¡lculo Eficiente de Gradientes

La **backpropagation** calcula los gradientes aplicando la **regla de la cadena** del cÃ¡lculo diferencial.

### Concepto Clave: El Error Î´[l]

```
Î´[l] = (âˆ‚J/âˆ‚a[l]) âŠ™ Ïƒ'(z[l])
```

- **âŠ™**: Producto de Hadamard (elemento a elemento)
- **Ïƒ'(z[l])**: Derivada de la funciÃ³n de activaciÃ³n

### Algoritmo de Backpropagation

```python
def backpropagation(X, y, cache):
    m = X.shape[1]
    L = len(cache)  # NÃºmero de capas
    
    # 1. Calcular error en la capa de salida
    delta_L = cache['A_L'] - y
    
    # 2. Propagar hacia atrÃ¡s
    gradientes = {}
    for l in reversed(range(1, L+1)):
        # Gradientes de pesos y sesgos
        gradientes[f'dW{l}'] = (1/m) * np.dot(delta, cache[f'A{l-1}'].T)
        gradientes[f'db{l}'] = (1/m) * np.sum(delta, axis=1, keepdims=True)
        
        # Error de la capa anterior
        if l > 1:
            delta = np.dot(cache[f'W{l}'].T, delta) * sigmoid_derivative(cache[f'Z{l-1}'])
    
    return gradientes
```

### Derivada de la Sigmoide

```python
def sigmoid_derivative(z):
    s = sigmoid(z)
    return s * (1 - s)
```

### PropagaciÃ³n hacia AtrÃ¡s - Paso a Paso

```
Capa de Salida (L) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â†‘                           â”‚
         â”‚ Calcular Î´[L]             â”‚
         â”‚                           â”‚
Capa Oculta 2 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
         â†‘                           â”‚
         â”‚ Î´[L-1] = W[L]áµ€Â·Î´[L] âŠ™ Ïƒ' â”‚ Backprop
         â”‚                           â”‚
Capa Oculta 1 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
         â†‘                           â”‚
         â”‚ Î´[L-2] = W[L-1]áµ€Â·Î´[L-1]  â”‚
         â”‚                           â”‚
Capa de Entrada â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### CÃ¡lculo de Gradientes Finales

**Para los pesos:**
```
âˆ‚J/âˆ‚W[l] = Î´[l] Â· a[lâˆ’1]áµ€
```

**Para los sesgos:**
```
âˆ‚J/âˆ‚b[l] = Î´[l]
```

## ğŸ”„ El Ciclo Completo de Aprendizaje

```python
def ciclo_entrenamiento(X, y, arquitectura, epochs, alpha):
    # Inicializar parÃ¡metros
    parametros = inicializar_red(arquitectura)
    
    for epoch in range(epochs):
        # 1. FORWARD PROPAGATION
        cache = forward_propagation(X, parametros)
        
        # 2. CALCULAR COSTO
        costo = calcular_costo(cache['A_L'], y)
        
        # 3. BACKWARD PROPAGATION
        gradientes = backpropagation(X, y, cache)
        
        # 4. ACTUALIZAR PARÃMETROS
        parametros = actualizar_parametros(parametros, gradientes, alpha)
        
        if epoch % 100 == 0:
            print(f"Epoch {epoch}: Costo = {costo:.4f}")
    
    return parametros
```

## ğŸ“Š VisualizaciÃ³n del Proceso

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 CICLO DE ENTRENAMIENTO              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                     â”‚
â”‚  1. Forward Pass                                    â”‚
â”‚     X â†’ Z1 â†’ A1 â†’ Z2 â†’ A2 â†’ ... â†’ Å¶                â”‚
â”‚                                                     â”‚
â”‚  2. Calcular PÃ©rdida                               â”‚
â”‚     L = (Y - Å¶)Â²                                    â”‚
â”‚                                                     â”‚
â”‚  3. Backward Pass                                   â”‚
â”‚     âˆ‚L/âˆ‚Å¶ â†’ âˆ‚L/âˆ‚W[L] â†’ ... â†’ âˆ‚L/âˆ‚W[1]              â”‚
â”‚                                                     â”‚
â”‚  4. Actualizar ParÃ¡metros                          â”‚
â”‚     W = W - Î±Â·âˆ‚L/âˆ‚W                                 â”‚
â”‚                                                     â”‚
â”‚  5. Repetir hasta convergencia                     â”‚
â”‚                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ’¡ Consejos PrÃ¡cticos

### Elegir la Tasa de Aprendizaje

```python
# Prueba diferentes valores
learning_rates = [0.001, 0.01, 0.1, 1.0]

for lr in learning_rates:
    modelo = entrenar(X, y, learning_rate=lr)
    print(f"LR={lr}: Costo Final={modelo.costo:.4f}")
```

### Monitorear el Entrenamiento

```python
import matplotlib.pyplot as plt

def plot_training(historial_costos):
    plt.plot(historial_costos)
    plt.xlabel('Ã‰poca')
    plt.ylabel('Costo')
    plt.title('EvoluciÃ³n del Costo durante el Entrenamiento')
    plt.show()
```

---

## ğŸ“š Referencias

- Goodfellow, I., Bengio, Y., & Courville, A. (2016). *Deep learning*. MIT Press.
- Mazur, M. (2015). A Step by Step Backpropagation Example.
- Ng, A. (2017). Neural Networks and Deep Learning. Coursera.

---

**Anterior:** [â† Blog 2: Fundamentos del Deep Learning](02-fundamentos-deep-learning-redes-neuronales.md)

**PrÃ³ximo:** [Blog 4: AplicaciÃ³n PrÃ¡ctica con Keras â†’](04-aplicacion-practica-keras.md)